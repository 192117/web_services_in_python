# Описание заданий

## 1. **_Практическое задание по Beautiful Soup._**

**Часть 1:**

В этом задании вам необходимо реализовать парсер для сбора статистики со страниц Википедии. Чтобы упростить вашу задачу,
необходимые страницы уже скачаны и сохранены на файловой системе в директории wiki/ (Например, страница 
https://en.wikipedia.org/wiki/Stone_Age сохранена файле wiki/Stone_Age). Архив страниц _**wiki.rar**_.

Парсер реализован в виде функции **parse**, которая принимает на вход один параметр: **path_to_file** — путь до файла, 
содержащий _html_ код страницы википедии. Гарантируется, что такой путь существует. Ваша задача — прочитать файл, пройтись
**Beautiful Soup** по статье, найти её тело (это **\<div id="bodyContent">**) и внутри него подсчитать:

- Количество картинок (img) с шириной (width) не меньше 200. Например: \<img width="200">, но не \<img> и не 
\<img width="199">

- Количество заголовков (h1, h2, h3, h4, h5, h6), первая буква текста внутри которых соответствует заглавной букве E, T 
или C. Например: \<h1>End\</h1> или \<h5>\<span>Contents\</span>\</h5>, но не \<h1>About\</h1> и не \<h2>end\</h2> и не 
\<h3>\<span>1\</span>\<span>End\</span>\</h3>

- Длину максимальной последовательности ссылок, между которыми нет других тегов, открывающихся или закрывающихся. 
Например: \<p>\<span>\<a>\</a>\</span>, **\<a>\</a>, \<a>\</a>**\</p> - тут 2 ссылки подряд, т.к. закрывающийся span 
прерывает последовательность. \<p>**\<a>\<span>\</span>\</a>, \<a>\</a>, \<a>\</a>**\</p> - а тут 3 ссылки подряд, т.к. 
span находится внутри ссылки, а не между ссылками.

- Количество списков (ul, ol), не вложенных в другие списки. Например: **\<ol>**\<li>\</li>\</ol>, 
**\<ul>**\<li>\<ol>\<li>\</li>\</ol>\</li>\</ul> - два не вложенных списка (и один вложенный)

Результатом работы функции parse будет **список четырех чисел**, посчитанных по формулам выше. В качестве шаблона для 
вашего решения **используйте следующий код**:

```
from bs4 import BeautifulSoup
import unittest

def parse(path_to_file):    
    # Поместите ваш код здесь.
    # ВАЖНО!!!
    # При открытии файла, добавьте в функцию open необязательный параметр
    # encoding='utf-8', его отсутствие в коде будет вызвать падение вашего
    # решения на грейдере с ошибкой UnicodeDecodeError
    return [imgs, headers, linkslen, lists]


class TestParse(unittest.TestCase):
    def test_parse(self):
        test_cases = (
            ('wiki/Stone_Age', [13, 10, 12, 40]),
            ('wiki/Brain', [19, 5, 25, 11]),
            ('wiki/Artificial_intelligence', [8, 19, 13, 198]),
            ('wiki/Python_(programming_language)', [2, 5, 17, 41]),
            ('wiki/Spectrogram', [1, 2, 4, 7]),)

        for path, expected in test_cases:
            with self.subTest(path=path, expected=expected):
                self.assertEqual(parse(path), expected)


if __name__ == '__main__':
    unittest.main()
```

В пункте про последовательность ссылок вы можете ошибиться с результатом, если решите использовать метод find_next(). 
Обратите внимание, что хотя find_next находит тег, идущий сразу за текущим, этот тег может оказаться вложенным в 
текущий, а не быть его следующим соседом. Возможно, нужно использовать другой метод или алгоритм.

Так же, не упустите момент, что данные во всех пунктах нужно искать внутри **_\<div id="bodyContent">_**, а не по всей 
странице.

**Пример работы функции parse:**

```
>>> parse("wiki/Stone_Age")

>>> [13, 10, 12, 40]
```

Несколько других примеров работы вы можете посмотреть в тестах из шаблона кода выше.

Во время проверки на сервере будут доступны только стандартные модули и bs4, сеть не доступна. Ваше решение будет 
проверяться, как на наборе страниц из приложенного архива, так и на дополнительном наборе страниц википедии. 

**"Важное замечание! Не используйте для сбора статистики по странице регулярные выражения. Beautiful Soup в своей работе 
использует специализированные парсеры, которые позволяют корректно обрабатывать невалидные (содержащие ошибки, 
например: незакрытый тег) html страницы. Статистика, собранная с помощью модуля re, на таких страницах будет возвращать 
не верное значение."**

**Часть 2:**

В этом задании продолжаем работать со страницами из wikipedia. Необходимо реализовать механизм сбора статистики по 
нескольким страницам. Сложность задачи состоит в том, что сначала нужно будет определить страницы, с которых необходимо 
собирать статистику. В качестве входных данных служат названия двух статей(страниц). Гарантируется, что файлы обеих 
статей есть в папке wiki и из первой статьи можно попасть в последнюю, переходя по ссылкам только на те статьи, копии 
которых есть в папке wiki.

Например, на вход подаются страницы: **Stone_Age** и **Python_(programming_language)**. В статье **Stone_Age** есть 
ссылка на **Brain**, в ней на **Artificial_intelligence**, а в ней на **Python_(programming_language)** и это 
кратчайший путь от **Stone_Age** до **Python_(programming_language)**. Ваша задача — найти самый короткий путь 
(гарантируется, что существует только один путь минимальной длины), а затем с помощью функции parse из предыдущего 
задания собрать статистику по всем статьям в найденном пути. 

Результат нужно вернуть в виде словаря, ключами которого являются имена статей, а значениями списки со статистикой. 
Для нашего примера правильный результат будет: 

```
{ 'Stone_Age': [13, 10, 12, 40], 
  'Brain': [19, 5, 25, 11], 
  'Artificial_intelligence': [8, 19, 13, 198], 
  'Python_(programming_language)': [2, 5, 17, 41] 
}
```

Вам необходимо реализовать две функции:  **build_bridge** и **get_statistics**.    

```
def build_bridge(path, start_page, end_page):
    """возвращает список страниц, по которым можно перейти по ссылкам со start_page на
    end_page, начальная и конечная страницы включаются в результирующий список"""

    # напишите вашу реализацию логики по вычисления кратчайшего пути здесь


def get_statistics(path, start_page, end_page):
    """собирает статистику со страниц, возвращает словарь, где ключ - название страницы,
    значение - список со статистикой страницы"""

    # получаем список страниц, с которых необходимо собрать статистику 
    pages = build_bridge(path, start_page, end_page)
    # напишите вашу реализацию логики по сбору статистики здесь

    return statistic
```

Обе функции принимают на вход три параметра:**path** - путь до директории с сохраненными файлами из wikipedia,
**start_page** - название начальной страницы, **end_page** - название конечной страницы.

Функция **build_bridge** вычисляет кратчайший путь и возвращает список страниц в том порядке, в котором происходят 
переходы. Начальная и конечная страницы включаются в результирующий список. В случае, если название стартовой и 
конечной страницы совпадают, то результирующий список должен содержать только стартовую страницу. Получить все ссылки 
на странице можно разными способами, в том числе и с помощью регулярных выражений, например так:

```
with open(os.path.join(path, page), encoding="utf-8") as file:
    links = re.findall(r"(?<=/wiki/)[\w()]+", file.read())
```

Обратите внимание, что на страницах wikipedia могут встречаться ссылки на страницы, которых нет в директории wiki, 
такие ссылки должны игнорироваться. 

Пример работы функции **build_bridge**:

```
>>> result = build_bridge('wiki/', 'The_New_York_Times', 'Stone_Age')
>>> print(result)
['The_New_York_Times', 'London', 'Woolwich', 'Iron_Age', 'Stone_Age']
```

Функция **get_statistics** использует функцию **parse** и собирает статистику по страницам, найденным с помощью 
функции **build_bridge**. Пример работы функции **get_statistics**: 

```
>>> from pprint import pprint
>>> result = get_statistics('wiki/', 'The_New_York_Times', "Binyamina_train_station_suicide_bombing")
>>> pprint(result)
{'Binyamina_train_station_suicide_bombing': [1, 3, 6, 21],
 'Haifa_bus_16_suicide_bombing': [1, 4, 15, 23],
 'Second_Intifada': [9, 13, 14, 84],
 'The_New_York_Times': [5, 9, 8, 42]}
```

Вы можете использовать для проверки вашего решения тесты:

```
# Набор тестов для проверки студентами решений по заданию "Практическое задание
# по Beautiful Soup - 2". По умолчанию файл с решением называется solution.py,
# измените в импорте название модуля solution, если файл с решением имеет другое имя.

import unittest

from solution import build_bridge, get_statistics

STATISTICS = {
    'Artificial_intelligence': [8, 19, 13, 198],
    'Binyamina_train_station_suicide_bombing': [1, 3, 6, 21],
    'Brain': [19, 5, 25, 11],
    'Haifa_bus_16_suicide_bombing': [1, 4, 15, 23],
    'Hidamari_no_Ki': [1, 5, 5, 35],
    'IBM': [13, 3, 21, 33],
    'Iron_Age': [4, 8, 15, 22],
    'London': [53, 16, 31, 125],
    'Mei_Kurokawa': [1, 1, 2, 7],
    'PlayStation_3': [13, 5, 14, 148],
    'Python_(programming_language)': [2, 5, 17, 41],
    'Second_Intifada': [9, 13, 14, 84],
    'Stone_Age': [13, 10, 12, 40],
    'The_New_York_Times': [5, 9, 8, 42],
    'Wild_Arms_(video_game)': [3, 3, 10, 27],
    'Woolwich': [15, 9, 19, 38]}

TESTCASES = (
    ('wiki/', 'Stone_Age', 'Python_(programming_language)',
     ['Stone_Age', 'Brain', 'Artificial_intelligence', 'Python_(programming_language)']),

    ('wiki/', 'The_New_York_Times', 'Stone_Age',
     ['The_New_York_Times', 'London', 'Woolwich', 'Iron_Age', 'Stone_Age']),

    ('wiki/', 'Artificial_intelligence', 'Mei_Kurokawa',
     ['Artificial_intelligence', 'IBM', 'PlayStation_3', 'Wild_Arms_(video_game)',
      'Hidamari_no_Ki', 'Mei_Kurokawa']),

    ('wiki/', 'The_New_York_Times', "Binyamina_train_station_suicide_bombing",
     ['The_New_York_Times', 'Second_Intifada', 'Haifa_bus_16_suicide_bombing',
      'Binyamina_train_station_suicide_bombing']),

    ('wiki/', 'Stone_Age', 'Stone_Age',
     ['Stone_Age', ]),
)


class TestBuildBrige(unittest.TestCase):
    def test_build_bridge(self):
        for path, start_page, end_page, expected in TESTCASES:
            with self.subTest(path=path,
                              start_page=start_page,
                              end_page=end_page,
                              expected=expected):
                result = build_bridge(path, start_page, end_page)
                self.assertEqual(result, expected)


class TestGetStatistics(unittest.TestCase):
    def test_build_bridge(self):
        for path, start_page, end_page, expected in TESTCASES:
            with self.subTest(path=path,
                              start_page=start_page,
                              end_page=end_page,
                              expected=expected):
                result = get_statistics(path, start_page, end_page)
                self.assertEqual(result, {page: STATISTICS[page] for page in expected})


if __name__ == '__main__':
    unittest.main()
```

Ваше решение должно содержать реализацию функций **get_statistics**, **build_bridge** и **parse**. Вы можете 
дополнительно объявить в коде другие функции, если этого требует логика вашего решения. 

Как и в предыдущем задании, тестовая система будет проверять ваш код как на страницах приложенных к описанию, так и на 
другом наборе станиц wikipedia. Решение должно выполняться за приемлемое время. Мы понимаем, что рассмотрение алгоритма 
решения не входит в программу курса, поэтому предлагаем вам ознакомиться с этой темой самостоятельно. 

## 2. **_Конвертер валют._**

В этом задании придется написать свой конвертер валют (см. приложенный файл). Курсы валют нужно брать из API 
Центробанка. Документация по нему тут, потребуется только XML_daily.asp. **(Обратите внимание, что указанный в 
документации API протокол http больше не поддерживается при запросах с помощью requests.get, указывайте в строке 
запроса https)**  

В функцию convert(amount, cur_from, cur_to, date, requests) будет передана сумма amount в валюте с кодом cur_from, и её 
требуется перевести в валюту cur_to через рубль (код: RUR). Для запроса к API нужно использовать переданный requests, 
точнее, его метод get().

- Все суммы и курсы требуется хранить в Decimal, т.к. для финансовых данных вычисления с фиксированной точкой подходят 
больше.

- Конечный результат нужно округлить до 4-х знаков, перед тем как вернуть его из функции. Посмотрите метод quantize().

- Для некоторых валют курс возвращается из расчета не на одну денежную единицу указанной валюты, а на 10 или даже 100, 
поэтому у курса валюты в XML есть не только Value, но и Nominal, и справедлива формула: Nominal ед. валюты = Value 
рублей.

- При проверке на сервере сеть недоступна. В функцию будет передан фейковый requests, его интерфейс и response аналогичны 
настоящему. Если его использовать в объеме, требуемом для задания, разницы не будет заметно.